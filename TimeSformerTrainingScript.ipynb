{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import decord\n",
    "from einops import rearrange\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# For accessing Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "# Constants\n",
    "NUM_CLASSES = 14  # Number of crime categories\n",
    "class_names = {\n",
    "    1: \"Abuse\",\n",
    "    2: \"Arrest\",\n",
    "    3: \"Arson\",\n",
    "    4: \"Assault\",\n",
    "    5: \"Burglary\",\n",
    "    6: \"Explosion\",\n",
    "    7: \"Fighting\",\n",
    "    8: \"Normal\",\n",
    "    9: \"RoadAccidents\",\n",
    "    10: \"Robbery\",\n",
    "    11: \"Shooting\",\n",
    "    12: \"Shoplifting\",\n",
    "    13: \"Stealing\",\n",
    "    14: \"Vandalism\"\n",
    "}\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define LoRA layers\n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, r=8, lora_alpha=16):\n",
    "        super().__init__()\n",
    "        self.original = nn.Linear(in_features, out_features)\n",
    "        self.lora_down = nn.Linear(in_features, r, bias=False)\n",
    "        self.lora_up = nn.Linear(r, out_features, bias=False)\n",
    "        self.scale = lora_alpha / r\n",
    "\n",
    "        # Initialize LoRA weights\n",
    "        nn.init.normal_(self.lora_down.weight, std=1/r)\n",
    "        nn.init.zeros_(self.lora_up.weight)\n",
    "\n",
    "        # Freeze original weights\n",
    "        for param in self.original.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Original path + LoRA path\n",
    "        return self.original(x) + self.lora_up(self.lora_down(x)) * self.scale\n",
    "\n",
    "# Define TimeSformer model with LoRA\n",
    "class TimeSformerForVideoClassification(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim=768, depth=12, num_heads=12, num_frames=8,\n",
    "                 lora_rank=16, pretrained=True, pretrained_model_path=None):\n",
    "        super().__init__()\n",
    "        self.num_frames = num_frames\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = depth\n",
    "\n",
    "        # Load pretrained ViT as base model\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "\n",
    "        # If pretrained model path is provided, load weights\n",
    "        if pretrained and pretrained_model_path:\n",
    "            print(f\"Loading pretrained TimeSformer weights from {pretrained_model_path}\")\n",
    "            self._load_pretrained_weights(pretrained_model_path)\n",
    "\n",
    "        # Replace attention blocks with LoRA attention blocks\n",
    "        self._replace_attention_with_lora(lora_rank)\n",
    "\n",
    "        # Replace classifier head\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%})\")\n",
    "\n",
    "    def _load_pretrained_weights(self, pretrained_model_path):\n",
    "        try:\n",
    "            # Load pretrained weights\n",
    "            pretrained_dict = torch.load(pretrained_model_path, map_location='cpu')\n",
    "\n",
    "            # Handle different model formats\n",
    "            if 'model_state' in pretrained_dict:\n",
    "                # Original TimeSformer format\n",
    "                pretrained_dict = pretrained_dict['model_state']\n",
    "            elif 'state_dict' in pretrained_dict:\n",
    "                # PyTorch checkpoint format\n",
    "                pretrained_dict = pretrained_dict['state_dict']\n",
    "\n",
    "            # Filter out irrelevant keys and adapt key names\n",
    "            model_dict = self.vit.state_dict()\n",
    "            pretrained_dict = {k.replace('backbone.', ''): v for k, v in pretrained_dict.items()\n",
    "                              if 'backbone.' in k and k.replace('backbone.', '') in model_dict}\n",
    "\n",
    "            # Load weights\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.vit.load_state_dict(model_dict)\n",
    "            print(f\"Successfully loaded pretrained TimeSformer weights\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pretrained weights: {e}\")\n",
    "            print(\"Initializing with random weights\")\n",
    "\n",
    "    def _replace_attention_with_lora(self, lora_rank):\n",
    "        \"\"\"\n",
    "        Replace self-attention query, key, value projections with LoRA versions\n",
    "        \"\"\"\n",
    "        for i, block in enumerate(self.vit.blocks):\n",
    "            # Replace q, k, v projections in self-attention\n",
    "            qkv_weight_shape = block.attn.qkv.weight.shape\n",
    "            qkv_in_features = qkv_weight_shape[1]\n",
    "            qkv_out_features = qkv_weight_shape[0]\n",
    "\n",
    "            # Store original weights\n",
    "            original_qkv = block.attn.qkv\n",
    "\n",
    "            # Create LoRA version of qkv projection\n",
    "            lora_qkv = LoRALinear(qkv_in_features, qkv_out_features, r=lora_rank)\n",
    "\n",
    "            # Initialize with original weights\n",
    "            lora_qkv.original.weight.data = original_qkv.weight.data.clone()\n",
    "            if original_qkv.bias is not None:\n",
    "                lora_qkv.original.bias.data = original_qkv.bias.data.clone()\n",
    "\n",
    "            # Replace original with LoRA version\n",
    "            block.attn.qkv = lora_qkv\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, num_frames, channels, height, width]\n",
    "        batch_size, num_frames, channels, height, width = x.shape\n",
    "\n",
    "        # Reshape to [batch_size * num_frames, channels, height, width]\n",
    "        x = x.view(-1, channels, height, width)\n",
    "\n",
    "        # Forward through ViT\n",
    "        x = self.vit.patch_embed(x)\n",
    "        cls_token = self.vit.cls_token.expand(batch_size * num_frames, -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = self.vit.pos_drop(x + self.vit.pos_embed)\n",
    "\n",
    "        # Forward through transformer blocks\n",
    "        for block in self.vit.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.vit.norm(x)\n",
    "\n",
    "        # Take cls token output\n",
    "        x = x[:, 0]\n",
    "\n",
    "        # Reshape back to [batch_size, num_frames, embed_dim]\n",
    "        x = x.view(batch_size, num_frames, -1)\n",
    "\n",
    "        # Average pooling over frames dimension\n",
    "        x = torch.mean(x, dim=1)\n",
    "\n",
    "        # Classification head\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define dataset and data loading functions\n",
    "def load_data_from_directory(data_dir):\n",
    "    \"\"\"\n",
    "    Load video paths and labels from directory structure\n",
    "    Each class should be in a separate folder\n",
    "    \"\"\"\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_id, class_name in class_names.items():\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if not os.path.exists(class_dir):\n",
    "            print(f\"Warning: Class directory {class_dir} not found\")\n",
    "            continue\n",
    "\n",
    "        for video_file in os.listdir(class_dir):\n",
    "            if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "                video_path = os.path.join(class_dir, video_file)\n",
    "                video_paths.append(video_path)\n",
    "                labels.append(class_id - 1)  # Convert to 0-indexed\n",
    "\n",
    "    return video_paths, labels\n",
    "\n",
    "def split_data(video_paths, labels, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Split data into train, validation, and test sets\n",
    "    \"\"\"\n",
    "    # First split into train and temp (val + test)\n",
    "    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "        video_paths, labels, test_size=(1-train_ratio), stratify=labels, random_state=42\n",
    "    )\n",
    "\n",
    "    # Then split temp into val and test\n",
    "    val_size = val_ratio / (1 - train_ratio)\n",
    "    val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "        temp_paths, temp_labels, test_size=(1-val_size), stratify=temp_labels, random_state=42\n",
    "    )\n",
    "\n",
    "    return (train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels)\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for video classification\n",
    "    \"\"\"\n",
    "    def __init__(self, video_paths, labels, transform=None, num_frames=8, target_size=(224, 224)):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            # Load video\n",
    "            vr = decord.VideoReader(video_path)\n",
    "            total_frames = len(vr)\n",
    "\n",
    "            # Sample frames uniformly\n",
    "            frame_indices = np.linspace(0, total_frames - 1, self.num_frames, dtype=int)\n",
    "\n",
    "            # Get frames\n",
    "            frames = vr.get_batch(frame_indices).asnumpy()\n",
    "\n",
    "            # Process frames\n",
    "            processed_frames = []\n",
    "            for frame in frames:\n",
    "                # Convert to RGB\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, self.target_size)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                processed_frames.append(frame)\n",
    "\n",
    "            # Stack frames\n",
    "            frames_tensor = torch.stack(processed_frames)\n",
    "\n",
    "            # Rearrange to [num_frames, channels, height, width]\n",
    "            #frames_tensor = frames_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "            return frames_tensor, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading video {video_path}: {e}\")\n",
    "            # Return a dummy tensor in case of error\n",
    "            dummy_tensor = torch.zeros((self.num_frames, 3, self.target_size[0], self.target_size[1]))\n",
    "            return dummy_tensor, torch.tensor(0, dtype=torch.long)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10,\n",
    "               scheduler=None, checkpoint_path=\"checkpoints\", best_model_path=\"checkpoints/best_model.pth\",\n",
    "               start_epoch=0):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \"\"\"\n",
    "    # Make sure checkpoint directory exists in Drive\n",
    "    drive_checkpoint_path = \"/content/drive/MyDrive/crime_classification_checkpoints\"\n",
    "    os.makedirs(drive_checkpoint_path, exist_ok=True)\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    # Create results directory\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "    # Load previous metrics if resuming training\n",
    "    if start_epoch > 0:\n",
    "        try:\n",
    "            with open(os.path.join(drive_checkpoint_path, \"metrics.json\"), \"r\") as f:\n",
    "                metrics = json.load(f)\n",
    "                train_losses = metrics[\"train_losses\"]\n",
    "                train_accuracies = metrics[\"train_accuracies\"]\n",
    "                val_losses = metrics[\"val_losses\"]\n",
    "                val_accuracies = metrics[\"val_accuracies\"]\n",
    "\n",
    "                if val_accuracies:\n",
    "                    best_val_acc = max(val_accuracies)\n",
    "\n",
    "            print(f\"Loaded metrics from previous training session\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load previous metrics: {e}\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_predictions.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate epoch statistics\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = accuracy_score(train_targets, train_predictions)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "\n",
    "        print(f\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_predictions.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate validation statistics\n",
    "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_epoch_acc = accuracy_score(val_targets, val_predictions)\n",
    "\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accuracies.append(val_epoch_acc)\n",
    "\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "        # Update learning rate scheduler if provided\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save checkpoint for every epoch\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': epoch_loss,\n",
    "            'val_loss': val_epoch_loss,\n",
    "            'train_acc': epoch_acc,\n",
    "            'val_acc': val_epoch_acc,\n",
    "        }\n",
    "\n",
    "        if scheduler:\n",
    "            checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
    "\n",
    "        # Save to local checkpoint path\n",
    "        os.makedirs(checkpoint_path, exist_ok=True)\n",
    "        torch.save(checkpoint, os.path.join(checkpoint_path, f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "\n",
    "        # Also save to Google Drive\n",
    "        torch.save(checkpoint, os.path.join(drive_checkpoint_path, f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "\n",
    "        # Save best model based on validation accuracy\n",
    "        if val_epoch_acc > best_val_acc:\n",
    "            best_val_acc = val_epoch_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            # Also save to Drive\n",
    "            torch.save(model.state_dict(), os.path.join(drive_checkpoint_path, \"best_model.pth\"))\n",
    "            print(f\"Saved best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "        # Save metrics after each epoch\n",
    "        metrics = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"train_accuracies\": train_accuracies,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"val_accuracies\": val_accuracies,\n",
    "        }\n",
    "        with open(\"results/metrics.json\", \"w\") as f:\n",
    "            json.dump(metrics, f)\n",
    "\n",
    "        # Also save metrics to Drive\n",
    "        with open(os.path.join(drive_checkpoint_path, \"metrics.json\"), \"w\") as f:\n",
    "            json.dump(metrics, f)\n",
    "\n",
    "        # Generate and save confusion matrix and classification report\n",
    "        if epoch % 5 == 0 or epoch == num_epochs - 1:\n",
    "            cm = confusion_matrix(val_targets, val_predictions)\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                        xticklabels=[class_names[i+1] for i in range(NUM_CLASSES)],\n",
    "                        yticklabels=[class_names[i+1] for i in range(NUM_CLASSES)])\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('True')\n",
    "            plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"results/confusion_matrix_epoch_{epoch+1}.png\")\n",
    "            # Also save to Drive\n",
    "            plt.savefig(os.path.join(drive_checkpoint_path, f\"confusion_matrix_epoch_{epoch+1}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # Generate classification report\n",
    "            report = classification_report(\n",
    "                val_targets, val_predictions,\n",
    "                target_names=[class_names[i+1] for i in range(NUM_CLASSES)],\n",
    "                output_dict=True\n",
    "            )\n",
    "\n",
    "            # Save as JSON\n",
    "            with open(f\"results/classification_report_epoch_{epoch+1}.json\", \"w\") as f:\n",
    "                json.dump(report, f, indent=4)\n",
    "\n",
    "            # Also save to Drive\n",
    "            with open(os.path.join(drive_checkpoint_path, f\"classification_report_epoch_{epoch+1}.json\"), \"w\") as f:\n",
    "                json.dump(report, f, indent=4)\n",
    "\n",
    "    # Plot training and validation loss and accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/training_history.png\")\n",
    "    # Also save to Drive\n",
    "    plt.savefig(os.path.join(drive_checkpoint_path, \"training_history.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set\n",
    "    \"\"\"\n",
    "    # Create Drive directory for results\n",
    "    drive_results_path = \"/content/drive/MyDrive/crime_classification_results\"\n",
    "    os.makedirs(drive_results_path, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_predictions.extend(preds.cpu().numpy())\n",
    "            test_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = accuracy_score(test_targets, test_predictions)\n",
    "    test_precision = precision_score(test_targets, test_predictions, average='weighted')\n",
    "    test_recall = recall_score(test_targets, test_predictions, average='weighted')\n",
    "    test_f1 = f1_score(test_targets, test_predictions, average='weighted')\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(test_targets, test_predictions)\n",
    "\n",
    "    # Generate and save classification report\n",
    "    report = classification_report(\n",
    "        test_targets, test_predictions,\n",
    "        target_names=[class_names[i+1] for i in range(NUM_CLASSES)],\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    # Save detailed results\n",
    "    results = {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"test_precision\": test_precision,\n",
    "        \"test_recall\": test_recall,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "    with open(\"results/test_results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    # Also save to Drive\n",
    "    with open(os.path.join(drive_results_path, \"test_results.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[class_names[i+1] for i in range(NUM_CLASSES)],\n",
    "                yticklabels=[class_names[i+1] for i in range(NUM_CLASSES)])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - Test Set')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/test_confusion_matrix.png\")\n",
    "    # Also save to Drive\n",
    "    plt.savefig(os.path.join(drive_results_path, \"test_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function for inference on a single video\n",
    "def predict_video(model, video_path, num_frames=8, transform=None, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Make prediction on a single video\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    try:\n",
    "        # Load video\n",
    "        vr = decord.VideoReader(video_path)\n",
    "        total_frames = len(vr)\n",
    "\n",
    "        # Sample frames uniformly\n",
    "        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "\n",
    "        # Get frames\n",
    "        frames = vr.get_batch(frame_indices).asnumpy()\n",
    "\n",
    "        # Process frames\n",
    "        processed_frames = []\n",
    "        for frame in frames:\n",
    "            # Convert to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, target_size)\n",
    "            if transform:\n",
    "                frame = transform(frame)\n",
    "            processed_frames.append(frame)\n",
    "\n",
    "        # Stack frames\n",
    "        frames_tensor = torch.stack(processed_frames)\n",
    "\n",
    "        # Rearrange to [num_frames, channels, height, width]\n",
    "        frames_tensor = frames_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Add batch dimension\n",
    "        frames_tensor = frames_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(frames_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence, prediction = torch.max(probabilities, 1)\n",
    "\n",
    "        return {\n",
    "            'prediction': prediction.item(),\n",
    "            'predicted_class': class_names[prediction.item() + 1],\n",
    "            'confidence': confidence.item(),\n",
    "            'probabilities': {class_names[i+1]: float(prob) for i, prob in enumerate(probabilities[0])}\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Modified function to use manually downloaded pretrained weights\n",
    "def download_pretrained_weights(model_name=\"TimeSformer_divST_8x32_224_K400\"):\n",
    "    \"\"\"\n",
    "    Use manually downloaded TimeSformer weights from Google Drive\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Drive if in Colab\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Path to your manually downloaded weights in Google Drive\n",
    "    drive_model_path = \"/content/drive/MyDrive/pretrained_models/TimeSformer_divST_8x32_224_K400.pyth\"\n",
    "\n",
    "    # Create directory for pretrained models in the local runtime\n",
    "    os.makedirs(\"pretrained_models\", exist_ok=True)\n",
    "    local_path = f\"pretrained_models/{model_name}.pyth\"\n",
    "\n",
    "    # Copy from Drive to local runtime\n",
    "    if os.path.exists(drive_model_path):\n",
    "        print(f\"Copying pretrained weights from Drive to local runtime...\")\n",
    "        import shutil\n",
    "        shutil.copy(drive_model_path, local_path)\n",
    "        print(f\"Copied to {local_path}\")\n",
    "    else:\n",
    "        print(f\"Error: Model file not found at {drive_model_path}\")\n",
    "        return None\n",
    "\n",
    "    return local_path\n",
    "\n",
    "def main():\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Set parameters\n",
    "    num_frames = 8\n",
    "    batch_size = 8  # Reduced from 16 to 8 for T4 GPU\n",
    "    num_epochs = 20\n",
    "    learning_rate = 1e-4\n",
    "    embedding_dim = 768\n",
    "    num_heads = 12\n",
    "    depth = 12\n",
    "    lora_rank = 16\n",
    "\n",
    "    # Path to your dataset\n",
    "    data_root = \"/content/drive/MyDrive/Anamoly\"  # Update this to your actual dataset path\n",
    "\n",
    "    # Define transforms for training and validation/testing\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Get pretrained model path\n",
    "    pretrained_model_path = download_pretrained_weights()\n",
    "\n",
    "    # Load data from directory structure\n",
    "    print(\"Loading video data...\")\n",
    "    video_paths, labels = load_data_from_directory(data_root)\n",
    "    print(f\"Found {len(video_paths)} videos across {len(set(labels))} classes\")\n",
    "\n",
    "    # Split data\n",
    "    (train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels) = split_data(\n",
    "        video_paths, labels, train_ratio=0.7, val_ratio=0.15\n",
    "    )\n",
    "\n",
    "    print(f\"Training set: {len(train_paths)} videos\")\n",
    "    print(f\"Validation set: {len(val_paths)} videos\")\n",
    "    print(f\"Test set: {len(test_paths)} videos\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = VideoDataset(\n",
    "        train_paths, train_labels, transform=train_transform,\n",
    "        num_frames=num_frames, target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    val_dataset = VideoDataset(\n",
    "        val_paths, val_labels, transform=val_transform,\n",
    "        num_frames=num_frames, target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    test_dataset = VideoDataset(\n",
    "        test_paths, test_labels, transform=val_transform,\n",
    "        num_frames=num_frames, target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    print(\"Initializing TimeSformer model with LoRA fine-tuning...\")\n",
    "    model = TimeSformerForVideoClassification(\n",
    "        num_classes=NUM_CLASSES,\n",
    "        embed_dim=embedding_dim,\n",
    "        depth=depth,\n",
    "        num_heads=num_heads,\n",
    "        num_frames=num_frames,\n",
    "        lora_rank=lora_rank,\n",
    "        pretrained=True,\n",
    "        pretrained_model_path=pretrained_model_path\n",
    "    ).to(device)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only optimize LoRA parameters and classification head\n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': [p for n, p in model.named_parameters() if 'lora' in n], 'lr': learning_rate},\n",
    "        {'params': [p for n, p in model.named_parameters() if 'head' in n], 'lr': learning_rate * 10}\n",
    "    ], weight_decay=0.01)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    # Check for existing checkpoints in Drive\n",
    "    drive_checkpoint_path = \"/content/drive/MyDrive/crime_classification_checkpoints\"\n",
    "    start_epoch = 0\n",
    "\n",
    "    if os.path.exists(drive_checkpoint_path):\n",
    "        checkpoint_files = sorted([f for f in os.listdir(drive_checkpoint_path) if f.startswith(\"checkpoint_epoch_\")])\n",
    "\n",
    "        if checkpoint_files:\n",
    "            # Get the latest checkpoint\n",
    "            latest_checkpoint = os.path.join(drive_checkpoint_path, checkpoint_files[-1])\n",
    "            print(f\"Found checkpoint: {latest_checkpoint}\")\n",
    "\n",
    "            try:\n",
    "                # Load checkpoint\n",
    "                checkpoint = torch.load(latest_checkpoint)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint['epoch']\n",
    "\n",
    "                if scheduler and 'scheduler_state_dict' in checkpoint:\n",
    "                    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "                print(f\"Resuming training from epoch {start_epoch}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading checkpoint: {e}\")\n",
    "                print(\"Starting training from scratch\")\n",
    "                start_epoch = 0\n",
    "        else:\n",
    "            print(\"No checkpoint found, starting training from scratch\")\n",
    "    else:\n",
    "        print(\"No checkpoint directory found, starting training from scratch\")\n",
    "\n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    train_results = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        scheduler=scheduler,\n",
    "        checkpoint_path=\"checkpoints\",\n",
    "        best_model_path=\"checkpoints/best_model.pth\",\n",
    "        start_epoch=start_epoch\n",
    "    )\n",
    "\n",
    "    # Load best model for evaluation\n",
    "    best_model_drive_path = os.path.join(drive_checkpoint_path, \"best_model.pth\")\n",
    "    if os.path.exists(best_model_drive_path):\n",
    "        print(\"Loading best model from Drive for evaluation...\")\n",
    "        model.load_state_dict(torch.load(best_model_drive_path))\n",
    "    else:\n",
    "        print(\"Loading best model from local path for evaluation...\")\n",
    "        model.load_state_dict(torch.load(\"checkpoints/best_model.pth\"))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating on test set...\")\n",
    "    test_results = evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "    # Save model architecture for later use\n",
    "    model_info = {\n",
    "        \"num_classes\": NUM_CLASSES,\n",
    "        \"embed_dim\": embedding_dim,\n",
    "        \"depth\": depth,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"num_frames\": num_frames,\n",
    "        \"lora_rank\": lora_rank\n",
    "    }\n",
    "\n",
    "    with open(\"results/model_info.json\", \"w\") as f:\n",
    "        json.dump(model_info, f, indent=4)\n",
    "\n",
    "    # Also save to Drive\n",
    "    drive_results_path = \"/content/drive/MyDrive/crime_classification_results\"\n",
    "    os.makedirs(drive_results_path, exist_ok=True)\n",
    "    with open(os.path.join(drive_results_path, \"model_info.json\"), \"w\") as f:\n",
    "        json.dump(model_info, f, indent=4)\n",
    "\n",
    "    print(\"Training and evaluation complete!\")\n",
    "    print(f\"Best validation accuracy: {train_results['best_val_acc']:.4f}\")\n",
    "    print(f\"Test accuracy: {test_results['test_accuracy']:.4f}\")\n",
    "\n",
    "    # Example inference on a sample video\n",
    "    if test_paths:\n",
    "        sample_video = test_paths[0]\n",
    "        print(f\"Running inference on sample video: {sample_video}\")\n",
    "        prediction = predict_video(model, sample_video, num_frames=num_frames, transform=val_transform)\n",
    "\n",
    "        if prediction:\n",
    "            print(f\"Predicted class: {prediction['predicted_class']}\")\n",
    "            print(f\"Confidence: {prediction['confidence']:.4f}\")\n",
    "\n",
    "            # Save prediction to Drive\n",
    "            with open(os.path.join(drive_results_path, \"sample_prediction.json\"), \"w\") as f:\n",
    "                json.dump(prediction, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
