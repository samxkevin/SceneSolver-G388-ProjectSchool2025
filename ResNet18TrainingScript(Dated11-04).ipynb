{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install decord\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "import decord\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score, classification_report\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set paths\n",
    "UCF_CRIME_PATH = \"/content/drive/MyDrive/Anamoly2\"  # Update this path\n",
    "CHECKPOINT_DIR = \"/content/drive/MyDrive/timesformer_checkpoints\"\n",
    "RESULTS_DIR = \"/content/drive/MyDrive/ucf_crime_results\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Function to extract frames from videos\n",
    "def extract_frames(video_path, num_frames=8):\n",
    "    try:\n",
    "        vr = decord.VideoReader(video_path)\n",
    "        total_frames = len(vr)\n",
    "        if total_frames == 0:\n",
    "            print(f\"Warning: No frames in video {video_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Get evenly spaced frames\n",
    "        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "        frames = []\n",
    "        for idx in frame_indices:\n",
    "            frame = vr[int(idx)].asnumpy()  # Get numpy array\n",
    "            frames.append(frame)\n",
    "            \n",
    "        return np.stack(frames)  # Return shape: (num_frames, height, width, 3)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting frames from {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Custom VideoClassifier model (no TimeSformer dependency)\n",
    "class SimpleVideoClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, num_frames=8):\n",
    "        super().__init__()\n",
    "        # Use ResNet18 as base CNN\n",
    "        from torchvision.models import resnet18, ResNet18_Weights\n",
    "        \n",
    "        # Initialize ResNet with pretrained weights\n",
    "        base_model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # Remove the final classification layer\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        \n",
    "        # Add temporal modeling\n",
    "        self.temporal_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input x has shape [batch_size, channels=3, frames, height, width]\n",
    "        batch_size, channels, num_frames, height, width = x.shape\n",
    "        \n",
    "        # Reshape for frame-wise processing\n",
    "        x = x.permute(0, 2, 1, 3, 4)  # [batch, frames, channels, height, width]\n",
    "        x = x.reshape(batch_size * num_frames, channels, height, width)\n",
    "        \n",
    "        # Extract features from each frame\n",
    "        frame_features = self.feature_extractor(x)  # [batch*frames, 512, 1, 1]\n",
    "        frame_features = frame_features.reshape(batch_size, num_frames, -1)  # [batch, frames, 512]\n",
    "        \n",
    "        # Temporal pooling across frames\n",
    "        temporal_features = frame_features.transpose(1, 2)  # [batch, 512, frames]\n",
    "        pooled_features = self.temporal_pool(temporal_features).squeeze(-1)  # [batch, 512]\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Dataset class\n",
    "class UCFCrimeDataset(Dataset):\n",
    "    def __init__(self, video_paths, labels, transform=None, num_frames=8):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Extract frames\n",
    "        frames = extract_frames(video_path, self.num_frames)\n",
    "        if frames is None:  # Handle error case\n",
    "            frames = np.zeros((self.num_frames, 224, 224, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Convert to tensor [T, H, W, C] -> [T, C, H, W]\n",
    "        frame_tensors = []\n",
    "        for frame in frames:\n",
    "            frame_tensor = torch.from_numpy(frame).permute(2, 0, 1).float()  # [C, H, W]\n",
    "            if self.transform:\n",
    "                frame_tensor = self.transform(frame_tensor)\n",
    "            frame_tensors.append(frame_tensor)\n",
    "        \n",
    "        # Stack frames to get [T, C, H, W]\n",
    "        video_tensor = torch.stack(frame_tensors)\n",
    "        \n",
    "        # Reshape to [C, T, H, W] for 3D models\n",
    "        video_tensor = video_tensor.permute(1, 0, 2, 3)\n",
    "        \n",
    "        return video_tensor, label\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to load dataset with a test split\n",
    "def load_dataset_with_test():\n",
    "    \"\"\"\n",
    "    Load dataset with train, validation, and test splits\n",
    "    \"\"\"\n",
    "    # Find all video files and their labels\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    class_dirs = sorted([d for d in os.listdir(UCF_CRIME_PATH) \n",
    "                        if os.path.isdir(os.path.join(UCF_CRIME_PATH, d))])\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(class_dirs)}\n",
    "    \n",
    "    print(f\"Found {len(class_dirs)} classes: {class_dirs}\")\n",
    "    print(f\"Class to index mapping: {class_to_idx}\")\n",
    "    \n",
    "    # Save class mapping for later use\n",
    "    with open(os.path.join(CHECKPOINT_DIR, \"class_mapping.json\"), \"w\") as f:\n",
    "        json.dump(class_to_idx, f, indent=4)\n",
    "    \n",
    "    for cls_name in class_dirs:\n",
    "        cls_dir = os.path.join(UCF_CRIME_PATH, cls_name)\n",
    "        videos = glob(os.path.join(cls_dir, \"*.mp4\"))\n",
    "        videos.extend(glob(os.path.join(cls_dir, \"*.avi\")))\n",
    "        \n",
    "        print(f\"Found {len(videos)} videos in class {cls_name}\")\n",
    "        \n",
    "        for video_path in videos:\n",
    "            video_paths.append(video_path)\n",
    "            labels.append(class_to_idx[cls_name])\n",
    "    \n",
    "    if not video_paths:\n",
    "        raise ValueError(\"No video files found. Please check your dataset path.\")\n",
    "        \n",
    "    # First split: 80% for train+val, 20% for testing\n",
    "    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "        video_paths, labels, test_size=0.2, random_state=42, stratify=labels if len(set(labels)) > 1 else None\n",
    "    )\n",
    "    \n",
    "    # Second split: 80% of train_val for training, 20% for validation (which is 0.2 * 0.8 = 0.16 of total)\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_val_paths, train_val_labels, test_size=0.2, random_state=42, \n",
    "        stratify=train_val_labels if len(set(train_val_labels)) > 1 else None\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_paths)}\")\n",
    "    print(f\"Validation samples: {len(val_paths)}\")\n",
    "    print(f\"Test samples: {len(test_paths)}\")\n",
    "    \n",
    "    return train_paths, val_paths, test_paths, train_labels, val_labels, test_labels, len(class_dirs), class_to_idx\n",
    "\n",
    "# Save checkpoint function\n",
    "def save_checkpoint(model, optimizer, epoch, val_loss, val_acc, checkpoint_dir, filename, is_best=False, training_history=None):\n",
    "    \"\"\"\n",
    "    Save model checkpoint with comprehensive metadata\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'timestamp': time.time(),\n",
    "        'training_history': training_history\n",
    "    }\n",
    "    \n",
    "    # Save the checkpoint\n",
    "    filepath = os.path.join(checkpoint_dir, filename)\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved to {filepath}\")\n",
    "    \n",
    "    # If this is the best model, make a copy as best_model.pth\n",
    "    if is_best:\n",
    "        best_filepath = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "        torch.save(checkpoint, best_filepath)\n",
    "        print(f\"Best model saved to {best_filepath}\")\n",
    "\n",
    "# Function to find the latest checkpoint\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "    \"\"\"\n",
    "    Find the latest checkpoint file in the directory\n",
    "    \"\"\"\n",
    "    checkpoint_files = glob(os.path.join(checkpoint_dir, \"checkpoint_epoch_*.pth\"))\n",
    "    if not checkpoint_files:\n",
    "        return None\n",
    "    \n",
    "    # Sort by modification time (newest first)\n",
    "    checkpoint_files.sort(key=os.path.getmtime, reverse=True)\n",
    "    return checkpoint_files[0]\n",
    "\n",
    "# Function to evaluate the model and save comprehensive metrics\n",
    "def evaluate_model(model, test_loader, device, class_names, class_indices, results_dir):\n",
    "    \"\"\"\n",
    "    Evaluate the model and save comprehensive metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Running inference on test set...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=None, labels=range(len(class_names))\n",
    "    )\n",
    "    precision_avg, recall_avg, f1_avg, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Create classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    # Print summary results\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted Precision: {precision_avg:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall_avg:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {f1_avg:.4f}\")\n",
    "    \n",
    "    # Prepare results dictionary\n",
    "    results = {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision_per_class': {class_names[i]: float(precision[i]) for i in range(len(class_names))},\n",
    "        'recall_per_class': {class_names[i]: float(recall[i]) for i in range(len(class_names))},\n",
    "        'f1_per_class': {class_names[i]: float(f1[i]) for i in range(len(class_names))},\n",
    "        'support_per_class': {class_names[i]: int(support[i]) for i in range(len(class_names))},\n",
    "        'precision_weighted': float(precision_avg),\n",
    "        'recall_weighted': float(recall_avg), \n",
    "        'f1_weighted': float(f1_avg),\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    # Create results directory with timestamp\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    eval_dir = os.path.join(results_dir, f\"evaluation_{timestamp}\")\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results as JSON\n",
    "    with open(os.path.join(eval_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    # Save metrics as CSV for easy import to Excel/sheets\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Class': list(results['precision_per_class'].keys()),\n",
    "        'Precision': list(results['precision_per_class'].values()),\n",
    "        'Recall': list(results['recall_per_class'].values()),\n",
    "        'F1 Score': list(results['f1_per_class'].values()),\n",
    "        'Support': list(results['support_per_class'].values())\n",
    "    })\n",
    "    metrics_df.to_csv(os.path.join(eval_dir, 'metrics_by_class.csv'), index=False)\n",
    "    \n",
    "    # Save summary metrics\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Weighted Precision', 'Weighted Recall', 'Weighted F1'],\n",
    "        'Value': [\n",
    "            results['accuracy'], \n",
    "            results['precision_weighted'], \n",
    "            results['recall_weighted'], \n",
    "            results['f1_weighted']\n",
    "        ]\n",
    "    })\n",
    "    summary_df.to_csv(os.path.join(eval_dir, 'summary_metrics.csv'), index=False)\n",
    "    \n",
    "    # Save confusion matrix as CSV\n",
    "    cm_df = pd.DataFrame(\n",
    "        results['confusion_matrix'],\n",
    "        index=list(results['precision_per_class'].keys()),\n",
    "        columns=list(results['precision_per_class'].keys())\n",
    "    )\n",
    "    cm_df.to_csv(os.path.join(eval_dir, 'confusion_matrix.csv'))\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(eval_dir, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot metrics by class\n",
    "    metrics_to_plot = [\n",
    "        ('precision_per_class', 'Precision by Class'),\n",
    "        ('recall_per_class', 'Recall by Class'),\n",
    "        ('f1_per_class', 'F1 Score by Class')\n",
    "    ]\n",
    "    \n",
    "    for metric_key, title in metrics_to_plot:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        values = results[metric_key]\n",
    "        classes = list(values.keys())\n",
    "        scores = list(values.values())\n",
    "        \n",
    "        # Sort by class name for consistent display\n",
    "        sorted_data = sorted(zip(classes, scores))\n",
    "        classes, scores = zip(*sorted_data)\n",
    "        \n",
    "        bars = plt.bar(classes, scores, color='skyblue')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylim(0, 1.0)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                     f'{height:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(eval_dir, f\"{title.lower().replace(' ', '_')}.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "    # Plot training history if available\n",
    "    if os.path.exists(os.path.join(CHECKPOINT_DIR, \"training_history.json\")):\n",
    "        with open(os.path.join(CHECKPOINT_DIR, \"training_history.json\"), \"r\") as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        # Plot training & validation accuracy\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "        plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(eval_dir, 'accuracy_history.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot training & validation loss\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(history['train_loss'], label='Training Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(eval_dir, 'loss_history.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"Evaluation complete. Results saved to {eval_dir}\")\n",
    "    return results\n",
    "\n",
    "# Main training function\n",
    "def train():\n",
    "    print(\"Starting Video Classification training on UCF Crime Dataset\")\n",
    "    \n",
    "    # Load dataset with test split\n",
    "    train_paths, val_paths, test_paths, train_labels, val_labels, test_labels, num_classes, class_mapping = load_dataset_with_test()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = UCFCrimeDataset(train_paths, train_labels, transform)\n",
    "    val_dataset = UCFCrimeDataset(val_paths, val_labels, transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Save test set info for later evaluation\n",
    "    test_data = {\n",
    "        'test_paths': test_paths,\n",
    "        'test_labels': test_labels\n",
    "    }\n",
    "    with open(os.path.join(CHECKPOINT_DIR, \"test_data.json\"), \"w\") as f:\n",
    "        json.dump(test_data, f)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SimpleVideoClassifier(num_classes)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Set up training parameters\n",
    "    start_epoch = 0\n",
    "    num_epochs = 20  # Extended training duration\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Check for checkpoints to resume from\n",
    "    latest_checkpoint = find_latest_checkpoint(CHECKPOINT_DIR)\n",
    "    \n",
    "    if latest_checkpoint:\n",
    "        print(f\"Found checkpoint: {latest_checkpoint}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_val_acc = checkpoint.get('val_acc', 0.0)\n",
    "            \n",
    "            # Restore history if available\n",
    "            if 'training_history' in checkpoint and checkpoint['training_history'] is not None:\n",
    "                history = checkpoint['training_history']\n",
    "                \n",
    "            print(f\"Resuming from epoch {start_epoch} with validation accuracy {best_val_acc}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "            print(\"Starting from scratch instead.\")\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting from scratch.\")\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i+1) % 5 == 0:\n",
    "                print(f\"Batch {i+1}, Loss: {loss.item():.4f}, Acc: {100*correct/total:.2f}%\")\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Training Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "        \n",
    "        # Save training metrics\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save validation metrics\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Save regular checkpoint every epoch\n",
    "        checkpoint_filename = f\"checkpoint_epoch_{epoch+1}.pth\"\n",
    "        is_best = val_acc > best_val_acc\n",
    "        \n",
    "        if is_best:\n",
    "            best_val_acc = val_acc\n",
    "            print(f\"New best validation accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        save_checkpoint(\n",
    "            model, optimizer, epoch, val_loss, val_acc, \n",
    "            CHECKPOINT_DIR, checkpoint_filename, \n",
    "            is_best=is_best, \n",
    "            training_history=history\n",
    "        )\n",
    "        \n",
    "        # Always save a fallback \"last_checkpoint.pth\" - this ensures we can always resume\n",
    "        save_checkpoint(\n",
    "            model, optimizer, epoch, val_loss, val_acc, \n",
    "            CHECKPOINT_DIR, \"last_checkpoint.pth\", \n",
    "            is_best=False, \n",
    "            training_history=history\n",
    "        )\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    # Save the final model regardless of performance\n",
    "    final_checkpoint_path = os.path.join(CHECKPOINT_DIR, \"final_model.pth\")\n",
    "    torch.save({\n",
    "        'epoch': num_epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'training_history': history\n",
    "    }, final_checkpoint_path)\n",
    "    print(f\"Final model saved to {final_checkpoint_path}\")\n",
    "    \n",
    "    # Save training history as JSON\n",
    "    history_path = os.path.join(CHECKPOINT_DIR, \"training_history.json\")\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "    print(f\"Training history saved to {history_path}\")\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate():\n",
    "    print(\"Starting evaluation on test set\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_data_path = os.path.join(CHECKPOINT_DIR, \"test_data.json\")\n",
    "    if not os.path.exists(test_data_path):\n",
    "        print(\"Test data not found. Please run training first.\")\n",
    "        return\n",
    "    \n",
    "    with open(test_data_path, \"r\") as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    test_paths = test_data['test_paths']\n",
    "    test_labels = test_data['test_labels']\n",
    "    \n",
    "    # Load class mapping\n",
    "    with open(os.path.join(CHECKPOINT_DIR, \"class_mapping.json\"), \"r\") as f:\n",
    "        class_mapping = json.load(f)\n",
    "    \n",
    "    # Reverse the class mapping to get index to class name\n",
    "    idx_to_class = {int(v): k for k, v in class_mapping.items()}\n",
    "    class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "    \n",
    "    # Create test dataset and loader\n",
    "    test_dataset = UCFCrimeDataset(test_paths, test_labels, transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Choose model to evaluate\n",
    "    model_choices = {\n",
    "        \"1\": (\"best_model.pth\", \"Best validation model\"),\n",
    "        \"2\": (\"final_model.pth\", \"Final model (after all epochs)\"),\n",
    "        \"3\": (\"last_checkpoint.pth\", \"Last saved checkpoint\")\n",
    "    }\n",
    "    \n",
    "    print(\"\\nChoose a model to evaluate:\")\n",
    "    for key, (filename, description) in model_choices.items():\n",
    "        if os.path.exists(os.path.join(CHECKPOINT_DIR, filename)):\n",
    "            print(f\"{key}: {description}\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1/2/3): \")\n",
    "    while choice not in model_choices or not os.path.exists(os.path.join(CHECKPOINT_DIR, model_choices[choice][0])):\n",
    "        print(\"Invalid choice or model file not found.\")\n",
    "        choice = input(\"Enter choice (1/2/3): \")\n",
    "    \n",
    "    model_path = os.path.join(CHECKPOINT_DIR, model_choices[choice][0])\n",
    "    print(f\"Evaluating model: {model_path}\")\n",
    "    \n",
    "    # Load model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_classes = len(class_mapping)\n",
    "    model = SimpleVideoClassifier(num_classes)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(model, test_loader, device, class_names, class_mapping, RESULTS_DIR)\n",
    "\n",
    "# Main execution function - allows choosing between training and evaluation\n",
    "def main():\n",
    "    print(\"UCF Crime Video Classification - Training and Evaluation\")\n",
    "    print(\"1: Train model\")\n",
    "    print(\"2: Evaluate model\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1/2): \")\n",
    "    \n",
    "    if choice == '1':\n",
    "        train()\n",
    "    elif choice == '2':\n",
    "        evaluate()\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
